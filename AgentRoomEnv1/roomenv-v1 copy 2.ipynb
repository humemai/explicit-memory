{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.disabled = True\n",
    "\n",
    "from agent import DQNAgent\n",
    "\n",
    "for pretrain_semantic in [False, True]:\n",
    "    for test_seed in [0]:\n",
    "        for question_prob in [0.1, 0.5, 1.0]:\n",
    "            for question_interval in [1, 2, 4, 128]:\n",
    "                all_params = {\n",
    "                    \"env_str\": \"room_env:RoomEnv-v1\",\n",
    "                    \"env_config\": {\n",
    "                        \"des_size\": \"l\",\n",
    "                        \"question_prob\": question_prob,\n",
    "                        \"allow_random_human\": True,\n",
    "                        \"allow_random_question\": True,\n",
    "                        \"check_resources\": True,\n",
    "                        \"question_interval\": question_interval,\n",
    "                    },\n",
    "                    \"max_epsilon\": 1.0,\n",
    "                    \"min_epsilon\": 0.1,\n",
    "                    \"epsilon_decay_until\": 128*2,\n",
    "                    \"gamma\": 0.65,\n",
    "                    \"capacity\": {\"episodic\": 16, \"semantic\": 16, \"short\": 1},\n",
    "                    \"nn_params\": {\n",
    "                        \"hidden_size\": 64,\n",
    "                        \"num_layers\": 2,\n",
    "                        \"embedding_dim\": 32,\n",
    "                        \"v1_params\": {\n",
    "                            \"include_human\": \"sum\",\n",
    "                            \"human_embedding_on_object_location\": False,\n",
    "                        },\n",
    "                        \"v2_params\": None,\n",
    "                    },\n",
    "                    \"num_iterations\": 128*2,\n",
    "                    \"replay_buffer_size\": 64,\n",
    "                    \"warm_start\": 32,\n",
    "                    \"batch_size\": 16,\n",
    "                    \"target_update_interval\": 10,\n",
    "                    \"pretrain_semantic\": pretrain_semantic,\n",
    "                    \"run_test\": True,\n",
    "                    \"num_samples_for_results\": 10,\n",
    "                    \"train_seed\": test_seed+5,\n",
    "                    \"plotting_interval\": 10,\n",
    "                    \"device\": \"cpu\",\n",
    "                    \"test_seed\": test_seed,\n",
    "                    \"ddqn\": False,\n",
    "                    \"dueling_dqn\": False,\n",
    "                    \"default_root_dir\": \"./training_results/TRASH/\",\n",
    "                    \"split_reward_training\": False,\n",
    "                }\n",
    "\n",
    "                agent = DQNAgent(**all_params)\n",
    "                agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.disabled = True\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from agent import HandcraftedAgent\n",
    "\n",
    "for policy in tqdm([\"random\", \"episodic_only\", \"semantic_only\"]):\n",
    "    results = []\n",
    "    for test_seed in [0, 1, 2, 3, 4]:\n",
    "        for question_prob in [0.1, 0.5, 1.0]:\n",
    "            for question_interval in [1, 2, 4, 128]:\n",
    "                params = {\n",
    "                    \"env_config\": {\n",
    "                        \"des_size\": \"l\",\n",
    "                        \"question_prob\": question_prob,\n",
    "                        \"allow_random_human\": True,\n",
    "                        \"allow_random_question\": True,\n",
    "                        \"check_resources\": True,\n",
    "                        \"seed\": test_seed,\n",
    "                        \"question_interval\": question_interval,\n",
    "                    },\n",
    "                    \"env_str\": \"room_env:RoomEnv-v1\",\n",
    "                    \"policy\": policy,\n",
    "                    \"num_samples_for_results\": 10,\n",
    "                    \"pretrain_semantic\": False,\n",
    "                    \"default_root_dir\": \"./training_results/TRASH/\",\n",
    "                }\n",
    "                if policy == \"random\":\n",
    "                    params[\"capacity\"] = {\"episodic\": 16, \"semantic\": 16, \"short\": 1}\n",
    "                elif policy == \"episodic_only\":\n",
    "                    params[\"capacity\"] = {\"episodic\": 32, \"semantic\": 0, \"short\": 1}\n",
    "                else:\n",
    "                    params[\"capacity\"] = {\"episodic\": 0, \"semantic\": 32, \"short\": 1}\n",
    "\n",
    "                agent = HandcraftedAgent(**params)\n",
    "                agent.test()\n",
    "                agent.remove_results_from_disk()\n",
    "\n",
    "                results.append(np.mean(agent.scores))\n",
    "            print(policy, np.mean(results), np.std(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4fa60467db84093b604f3ff2433434f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.virtualenvs/human-memory/lib/python3.10/site-packages/gymnasium/envs/registration.py:513: DeprecationWarning: \u001b[33mWARN: The environment RoomEnv-v1 is out of date. You should consider upgrading to version `v2`.\u001b[0m\n",
      "  logger.deprecation(\n",
      "/home/tk/.virtualenvs/human-memory/lib/python3.10/site-packages/gymnasium/envs/registration.py:481: UserWarning: \u001b[33mWARN: The environment creator metadata doesn't include `render_modes`, contains: ['render.modes']\u001b[0m\n",
      "  logger.warn(\n",
      "/home/tk/.virtualenvs/human-memory/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:168: DeprecationWarning: \u001b[33mWARN: Current gymnasium version requires that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.deprecation(\n",
      "/home/tk/.virtualenvs/human-memory/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:181: DeprecationWarning: \u001b[33mWARN: Current gymnasium version requires that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.deprecation(\n",
      "/home/tk/.virtualenvs/human-memory/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:127: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method should be an int or np.int64, actual type: <class 'tuple'>\u001b[0m\n",
      "  logger.warn(f\"{pre} should be an int or np.int64, actual type: {type(obs)}\")\n",
      "/home/tk/.virtualenvs/human-memory/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/home/tk/.virtualenvs/human-memory/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:127: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method should be an int or np.int64, actual type: <class 'tuple'>\u001b[0m\n",
      "  logger.warn(f\"{pre} should be an int or np.int64, actual type: {type(obs)}\")\n",
      "/home/tk/.virtualenvs/human-memory/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random 30.120000000000005 2.5537423519219793\n",
      "episodic_only 47.68 2.553742351921979\n",
      "semantic_only 55.15999999999999 2.1067510531621894\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.disabled = True\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from agent import HandcraftedAgent\n",
    "\n",
    "for policy in tqdm([\"random\", \"episodic_only\", \"semantic_only\"]):\n",
    "    results = []\n",
    "    for test_seed in [0, 1, 2, 3, 4]:\n",
    "        params = {\n",
    "            \"env_config\": {\n",
    "                \"des_size\": \"l\",\n",
    "                \"question_prob\": 1.0,\n",
    "                \"allow_random_human\": False,\n",
    "                \"allow_random_question\": False,\n",
    "                \"check_resources\": True,\n",
    "                \"seed\": test_seed,\n",
    "                \"question_interval\": 1,\n",
    "            },\n",
    "            \"env_str\": \"room_env:RoomEnv-v1\",\n",
    "            \"policy\": policy,\n",
    "            \"num_samples_for_results\": 10,\n",
    "            \"pretrain_semantic\": False,\n",
    "            \"default_root_dir\": \"./training_results/TRASH/\",\n",
    "        }\n",
    "        if policy == \"random\":\n",
    "            params[\"capacity\"] = {\"episodic\": 16, \"semantic\": 16, \"short\": 1}\n",
    "        elif policy == \"episodic_only\":\n",
    "            params[\"capacity\"] = {\"episodic\": 32, \"semantic\": 0, \"short\": 1}\n",
    "        else:\n",
    "            params[\"capacity\"] = {\"episodic\": 0, \"semantic\": 32, \"short\": 1}\n",
    "\n",
    "        agent = HandcraftedAgent(**params)\n",
    "        agent.test()\n",
    "        agent.remove_results_from_disk()\n",
    "\n",
    "        results.append(np.mean(agent.scores))\n",
    "    print(policy, np.mean(results), np.std(results))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7c14ce45c674ffbe7e3a8bc18299264a1035542c780d18c0e8f0c585e044f28"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('dev-python3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
