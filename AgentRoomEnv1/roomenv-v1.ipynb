{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training RL agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.disabled = True\n",
    "\n",
    "from agent import DQNAgent\n",
    "\n",
    "for pretrain_semantic in [False, True]:\n",
    "    for test_seed in [0, 1, 2, 3, 4]:\n",
    "        params = {\n",
    "            \"env_str\": \"room_env:RoomEnv-v1\",\n",
    "            \"env_config\": {\n",
    "                \"des_size\": \"l\",\n",
    "                \"question_prob\": 1.0,\n",
    "                \"allow_random_human\": False,\n",
    "                \"allow_random_question\": False,\n",
    "                \"check_resources\": True,\n",
    "            },\n",
    "            \"max_epsilon\": 1.0,\n",
    "            \"min_epsilon\": 0.1,\n",
    "            \"epsilon_decay_until\": 128 * 128,\n",
    "            \"gamma\": 0.9,\n",
    "            \"capacity\": {\"episodic\": 16, \"semantic\": 16, \"short\": 1},\n",
    "            \"nn_params\": {\n",
    "                \"hidden_size\": 64,\n",
    "                \"num_layers\": 2,\n",
    "                \"embedding_dim\": 64,\n",
    "                \"v1_params\": {\n",
    "                    \"include_human\": \"sum\",\n",
    "                    \"human_embedding_on_object_location\": False,\n",
    "                },\n",
    "                \"v2_params\": None,\n",
    "                \"fuse_information\": \"sum\",\n",
    "            },\n",
    "            \"num_iterations\": 128 * 128,\n",
    "            \"replay_buffer_size\": 128 * 128,\n",
    "            \"warm_start\": 128 * 128 / 16,\n",
    "            \"batch_size\": 32,\n",
    "            \"target_update_interval\": 10,\n",
    "            \"pretrain_semantic\": pretrain_semantic,\n",
    "            \"run_test\": True,\n",
    "            \"num_samples_for_results\": 10,\n",
    "            \"train_seed\": test_seed + 5,\n",
    "            \"plotting_interval\": 10,\n",
    "            \"device\": \"cpu\",\n",
    "            \"test_seed\": test_seed,\n",
    "            \"ddqn\": True,\n",
    "            \"dueling_dqn\": True,\n",
    "            \"default_root_dir\": \"./training_results/TRASH/\",\n",
    "        }\n",
    "\n",
    "        agent = DQNAgent(**params)\n",
    "        agent.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing hand-crafted agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.disabled = True\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from agent import HandcraftedAgent\n",
    "\n",
    "for policy in tqdm([\"random\", \"episodic_only\", \"semantic_only\"]):\n",
    "    results = []\n",
    "    for test_seed in [0, 1, 2, 3, 4]:\n",
    "        params = {\n",
    "            \"env_config\": {\n",
    "                \"des_size\": \"l\",\n",
    "                \"question_prob\": 1.0,\n",
    "                \"allow_random_human\": True,\n",
    "                \"allow_random_question\": True,\n",
    "                \"check_resources\": True,\n",
    "                \"seed\": test_seed,\n",
    "            },\n",
    "            \"env_str\": \"room_env:RoomEnv-v1\",\n",
    "            \"policy\": policy,\n",
    "            \"num_samples_for_results\": 10,\n",
    "            \"pretrain_semantic\": False,\n",
    "            \"default_root_dir\": \"./training_results/TRASH/\",\n",
    "        }\n",
    "        if policy == \"random\":\n",
    "            params[\"capacity\"] = {\"episodic\": 16, \"semantic\": 16, \"short\": 1}\n",
    "        elif policy == \"episodic_only\":\n",
    "            params[\"capacity\"] = {\"episodic\": 32, \"semantic\": 0, \"short\": 1}\n",
    "        else:\n",
    "            params[\"capacity\"] = {\"episodic\": 0, \"semantic\": 32, \"short\": 1}\n",
    "\n",
    "        agent = HandcraftedAgent(**params)\n",
    "        agent.test()\n",
    "        agent.remove_results_from_disk()\n",
    "\n",
    "        results.append(np.mean(agent.scores))\n",
    "    print(policy, np.mean(results), np.std(results))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7c14ce45c674ffbe7e3a8bc18299264a1035542c780d18c0e8f0c585e044f28"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('dev-python3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
