{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-26 13:52:44,738] A new study created in memory with name: no-name-d1877b48-1207-4924-86c5-e1632a6d88e8\n",
      "/home/tk/.virtualenvs/human-memory/lib/python3.9/site-packages/stable_baselines3/common/policies.py:460: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
      "  warnings.warn(\n",
      "[I 2023-08-26 13:52:55,908] Trial 0 finished with value: 8.666666666666666 and parameters: {'gamma': 0.000285634655200047, 'max_grad_norm': 0.8805307489021439, 'gae_lambda': 0.1377125928003396, 'exponent_n_steps': 5, 'lr': 0.11240413887880535, 'ent_coef': 3.1643960353616967e-07, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 0 with value: 8.666666666666666.\n",
      "[I 2023-08-26 13:53:05,692] Trial 1 finished with value: 9.333333333333334 and parameters: {'gamma': 0.002970620027766817, 'max_grad_norm': 0.6079346013390916, 'gae_lambda': 0.16922736961156498, 'exponent_n_steps': 7, 'lr': 0.06084601794082003, 'ent_coef': 0.0048134336853121506, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 1 with value: 9.333333333333334.\n",
      "[I 2023-08-26 13:53:17,699] Trial 2 finished with value: 169.0 and parameters: {'gamma': 0.005158596121720041, 'max_grad_norm': 0.48362082216795405, 'gae_lambda': 0.1018988377469286, 'exponent_n_steps': 5, 'lr': 0.00193461454529426, 'ent_coef': 4.366402906473265e-08, 'ortho_init': True, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 2 with value: 169.0.\n",
      "[I 2023-08-26 13:53:26,974] Trial 3 finished with value: 246.66666666666666 and parameters: {'gamma': 0.016522391700577226, 'max_grad_norm': 1.0736933735088998, 'gae_lambda': 0.0032418717018412734, 'exponent_n_steps': 9, 'lr': 0.0016624652341949808, 'ent_coef': 4.0417159438077994e-08, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 3 with value: 246.66666666666666.\n",
      "[I 2023-08-26 13:53:36,393] Trial 4 finished with value: 9.333333333333334 and parameters: {'gamma': 0.0016315429139275076, 'max_grad_norm': 1.6429157524640063, 'gae_lambda': 0.05911111444170248, 'exponent_n_steps': 8, 'lr': 0.06613338092890607, 'ent_coef': 0.011689609969533365, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 3 with value: 246.66666666666666.\n",
      "[I 2023-08-26 13:53:45,338] Trial 5 finished with value: 95.33333333333333 and parameters: {'gamma': 0.09016367803070141, 'max_grad_norm': 4.644376546361343, 'gae_lambda': 0.0016811272170667263, 'exponent_n_steps': 10, 'lr': 2.050530966050809e-05, 'ent_coef': 1.1536883427804049e-08, 'ortho_init': True, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 3 with value: 246.66666666666666.\n",
      "[I 2023-08-26 13:53:55,407] Trial 6 finished with value: 185.0 and parameters: {'gamma': 0.04081108945780271, 'max_grad_norm': 1.5451846824998259, 'gae_lambda': 0.0036939587042096418, 'exponent_n_steps': 10, 'lr': 0.000854766782939148, 'ent_coef': 5.4026920213659035e-06, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 3 with value: 246.66666666666666.\n",
      "[I 2023-08-26 13:54:03,001] Trial 7 pruned. \n",
      "[I 2023-08-26 13:54:11,938] Trial 8 pruned. \n",
      "[I 2023-08-26 13:54:21,622] Trial 9 finished with value: 500.0 and parameters: {'gamma': 0.00014107442660152463, 'max_grad_norm': 1.9397063942552386, 'gae_lambda': 0.011699973530174844, 'exponent_n_steps': 9, 'lr': 0.006473981194686457, 'ent_coef': 4.2905282590519327e-07, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 13:54:31,649] Trial 10 finished with value: 500.0 and parameters: {'gamma': 0.00010880982459678757, 'max_grad_norm': 2.834447122141331, 'gae_lambda': 0.025778105742096772, 'exponent_n_steps': 6, 'lr': 0.0115501160662565, 'ent_coef': 1.3426846628609748e-06, 'ortho_init': True, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 13:54:41,316] Trial 11 finished with value: 107.66666666666667 and parameters: {'gamma': 0.00010779547428386203, 'max_grad_norm': 2.642317055054446, 'gae_lambda': 0.025485350593977704, 'exponent_n_steps': 6, 'lr': 0.014106752841862106, 'ent_coef': 8.169760275269356e-07, 'ortho_init': True, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 13:54:51,641] Trial 12 finished with value: 194.33333333333334 and parameters: {'gamma': 0.00011342324842840925, 'max_grad_norm': 2.520610687570479, 'gae_lambda': 0.01652418413376964, 'exponent_n_steps': 6, 'lr': 0.00899546735636073, 'ent_coef': 4.294040965983718e-05, 'ortho_init': True, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 13:55:03,434] Trial 13 finished with value: 110.33333333333333 and parameters: {'gamma': 0.000512659272171695, 'max_grad_norm': 2.5614868793021732, 'gae_lambda': 0.03227572588855306, 'exponent_n_steps': 4, 'lr': 0.01156476730634262, 'ent_coef': 5.691758021117208e-07, 'ortho_init': True, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 13:55:12,271] Trial 14 pruned. \n",
      "[I 2023-08-26 13:55:21,570] Trial 15 finished with value: 186.66666666666666 and parameters: {'gamma': 0.0007865445974839303, 'max_grad_norm': 1.837533429115977, 'gae_lambda': 0.044579069929559935, 'exponent_n_steps': 7, 'lr': 0.0034982742039533126, 'ent_coef': 1.80193308466741e-07, 'ortho_init': True, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 13:55:25,908] Trial 16 pruned. \n",
      "[I 2023-08-26 13:55:36,532] Trial 17 finished with value: 143.33333333333334 and parameters: {'gamma': 0.0008369805676704471, 'max_grad_norm': 1.9461747062370054, 'gae_lambda': 0.00923993007983354, 'exponent_n_steps': 5, 'lr': 0.004091721767460763, 'ent_coef': 0.0914652232625392, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 13:55:41,326] Trial 18 pruned. \n",
      "[I 2023-08-26 13:55:45,880] Trial 19 pruned. \n",
      "[I 2023-08-26 13:55:52,949] Trial 20 pruned. \n",
      "[I 2023-08-26 13:55:57,336] Trial 21 pruned. \n",
      "[I 2023-08-26 13:56:01,664] Trial 22 pruned. \n",
      "[I 2023-08-26 13:56:11,027] Trial 23 finished with value: 354.0 and parameters: {'gamma': 0.0010800190792174715, 'max_grad_norm': 1.393966883458546, 'gae_lambda': 0.0010360267660718657, 'exponent_n_steps': 8, 'lr': 0.001095564165715131, 'ent_coef': 6.691661340182576e-08, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 13:56:20,580] Trial 24 finished with value: 500.0 and parameters: {'gamma': 0.0011990404828707206, 'max_grad_norm': 2.0002111520809205, 'gae_lambda': 0.0022679616992996167, 'exponent_n_steps': 8, 'lr': 0.005659467405230782, 'ent_coef': 1.129446826739357e-06, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 13:56:30,109] Trial 25 finished with value: 218.66666666666666 and parameters: {'gamma': 0.0003876312190608297, 'max_grad_norm': 2.179150516888456, 'gae_lambda': 0.012231612623809812, 'exponent_n_steps': 7, 'lr': 0.007429058026867876, 'ent_coef': 1.1622006831039878e-06, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 13:56:34,947] Trial 26 pruned. \n",
      "[I 2023-08-26 13:56:45,082] Trial 27 finished with value: 500.0 and parameters: {'gamma': 0.0013010981939661037, 'max_grad_norm': 1.993219152225749, 'gae_lambda': 0.021536899197472956, 'exponent_n_steps': 6, 'lr': 0.003975459055610065, 'ent_coef': 2.5806042782391445e-06, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 13:56:49,668] Trial 28 pruned. \n",
      "[I 2023-08-26 13:56:55,864] Trial 29 pruned. \n",
      "[I 2023-08-26 13:57:00,642] Trial 30 pruned. \n",
      "[I 2023-08-26 13:57:10,423] Trial 31 finished with value: 198.33333333333334 and parameters: {'gamma': 0.0017625167680031715, 'max_grad_norm': 2.13628934146939, 'gae_lambda': 0.018109108821054525, 'exponent_n_steps': 6, 'lr': 0.0034312406575706853, 'ent_coef': 1.9981304057827343e-06, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 13:57:21,241] Trial 32 finished with value: 96.0 and parameters: {'gamma': 0.0012336691555258155, 'max_grad_norm': 1.8723895191445756, 'gae_lambda': 0.02020209351336274, 'exponent_n_steps': 5, 'lr': 0.004611995376090738, 'ent_coef': 2.420199087453419e-06, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 13:57:25,873] Trial 33 pruned. \n",
      "[I 2023-08-26 13:57:31,056] Trial 34 pruned. \n",
      "[I 2023-08-26 13:57:43,397] Trial 35 finished with value: 500.0 and parameters: {'gamma': 0.0023068363562218533, 'max_grad_norm': 0.8491021137483807, 'gae_lambda': 0.025565506190237917, 'exponent_n_steps': 4, 'lr': 0.006186581347033457, 'ent_coef': 1.814943104686366e-06, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 13:57:49,115] Trial 36 pruned. \n",
      "[I 2023-08-26 13:57:58,567] Trial 37 finished with value: 164.0 and parameters: {'gamma': 0.0043931625526418775, 'max_grad_norm': 1.6310427616972918, 'gae_lambda': 0.007202239648282937, 'exponent_n_steps': 7, 'lr': 0.0018844280518508375, 'ent_coef': 8.024199065508207e-07, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 13:58:02,808] Trial 38 pruned. \n",
      "[I 2023-08-26 13:58:07,064] Trial 39 pruned. \n",
      "[I 2023-08-26 13:58:11,874] Trial 40 pruned. \n",
      "[I 2023-08-26 13:58:17,969] Trial 41 pruned. \n",
      "[I 2023-08-26 13:58:23,919] Trial 42 pruned. \n",
      "[I 2023-08-26 13:58:31,278] Trial 43 pruned. \n",
      "[I 2023-08-26 13:58:42,173] Trial 44 finished with value: 446.0 and parameters: {'gamma': 0.0013891695238419518, 'max_grad_norm': 0.976559698653404, 'gae_lambda': 0.03864755507888607, 'exponent_n_steps': 5, 'lr': 0.005311100685530134, 'ent_coef': 5.187789478570047e-07, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 13:58:47,619] Trial 45 pruned. \n",
      "[I 2023-08-26 13:58:52,353] Trial 46 pruned. \n",
      "[I 2023-08-26 13:58:56,945] Trial 47 pruned. \n",
      "[I 2023-08-26 13:59:06,580] Trial 48 finished with value: 120.33333333333333 and parameters: {'gamma': 0.000835880320101651, 'max_grad_norm': 1.9096268944234447, 'gae_lambda': 0.010381906134165541, 'exponent_n_steps': 8, 'lr': 0.016228727451763767, 'ent_coef': 2.708471846812657e-07, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 13:59:12,812] Trial 49 pruned. \n",
      "[I 2023-08-26 13:59:17,916] Trial 50 pruned. \n",
      "[I 2023-08-26 13:59:23,835] Trial 51 pruned. \n",
      "[I 2023-08-26 13:59:30,270] Trial 52 pruned. \n",
      "[I 2023-08-26 13:59:40,794] Trial 53 finished with value: 469.3333333333333 and parameters: {'gamma': 0.0006646684869875704, 'max_grad_norm': 0.9792417271718831, 'gae_lambda': 0.034263137039287815, 'exponent_n_steps': 6, 'lr': 0.011883992316513074, 'ent_coef': 1.4788671801792469e-06, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 13:59:45,415] Trial 54 pruned. \n",
      "[I 2023-08-26 13:59:50,326] Trial 55 pruned. \n",
      "[I 2023-08-26 14:00:00,426] Trial 56 finished with value: 160.0 and parameters: {'gamma': 0.0009659320751931667, 'max_grad_norm': 1.2769729419124152, 'gae_lambda': 0.02262544833167248, 'exponent_n_steps': 7, 'lr': 0.010353243394843219, 'ent_coef': 8.035794049262708e-07, 'ortho_init': True, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 14:00:09,812] Trial 57 finished with value: 469.0 and parameters: {'gamma': 0.001794611223846277, 'max_grad_norm': 1.4256089667891543, 'gae_lambda': 0.014610545667365677, 'exponent_n_steps': 9, 'lr': 0.0030486168113103705, 'ent_coef': 4.520728111118678e-06, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 14:00:15,691] Trial 58 pruned. \n",
      "[I 2023-08-26 14:00:21,171] Trial 59 pruned. \n",
      "[I 2023-08-26 14:00:30,465] Trial 60 finished with value: 319.3333333333333 and parameters: {'gamma': 0.0006486606407514615, 'max_grad_norm': 1.7363113159669017, 'gae_lambda': 0.019200587917756938, 'exponent_n_steps': 7, 'lr': 0.004037668941143824, 'ent_coef': 2.2571188440377126e-06, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 14:00:35,117] Trial 61 pruned. \n",
      "[I 2023-08-26 14:00:44,420] Trial 62 finished with value: 500.0 and parameters: {'gamma': 0.0025853394980723996, 'max_grad_norm': 1.4427004280819977, 'gae_lambda': 0.02604586326636466, 'exponent_n_steps': 9, 'lr': 0.00323489640691711, 'ent_coef': 9.990814309869586e-07, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 14:00:48,918] Trial 63 pruned. \n",
      "[I 2023-08-26 14:00:58,652] Trial 64 finished with value: 500.0 and parameters: {'gamma': 0.00012506072981984437, 'max_grad_norm': 2.077229733715489, 'gae_lambda': 0.03527076960656495, 'exponent_n_steps': 8, 'lr': 0.004071701822654246, 'ent_coef': 2.021435563391134e-06, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 14:01:08,725] Trial 65 finished with value: 500.0 and parameters: {'gamma': 0.0001132214869471607, 'max_grad_norm': 2.024417222717744, 'gae_lambda': 0.025310790847116647, 'exponent_n_steps': 8, 'lr': 0.0019307043229620006, 'ent_coef': 2.5544609668745835e-06, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 14:01:18,290] Trial 66 finished with value: 259.3333333333333 and parameters: {'gamma': 0.0001396417954237627, 'max_grad_norm': 2.3693091897442495, 'gae_lambda': 0.019527258639527638, 'exponent_n_steps': 9, 'lr': 0.004406674865619113, 'ent_coef': 8.191232234704951e-07, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 14:01:22,636] Trial 67 pruned. \n",
      "[I 2023-08-26 14:01:27,064] Trial 68 pruned. \n",
      "[I 2023-08-26 14:01:33,135] Trial 69 pruned. \n",
      "[I 2023-08-26 14:01:47,381] Trial 70 finished with value: 500.0 and parameters: {'gamma': 0.00032035570982154505, 'max_grad_norm': 2.3993666308614543, 'gae_lambda': 0.0184316556500091, 'exponent_n_steps': 8, 'lr': 0.003441653498843471, 'ent_coef': 3.5500723610432306e-06, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 14:01:52,860] Trial 71 pruned. \n",
      "[I 2023-08-26 14:02:03,658] Trial 72 finished with value: 500.0 and parameters: {'gamma': 0.00012158165964695257, 'max_grad_norm': 2.6998156098171435, 'gae_lambda': 0.022963933251661354, 'exponent_n_steps': 9, 'lr': 0.002176223436338598, 'ent_coef': 2.673672929412732e-06, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 14:02:08,999] Trial 73 pruned. \n",
      "[I 2023-08-26 14:02:19,554] Trial 74 finished with value: 500.0 and parameters: {'gamma': 0.00016846930267509064, 'max_grad_norm': 1.935026193353569, 'gae_lambda': 0.04155824349762039, 'exponent_n_steps': 7, 'lr': 0.004252985482242853, 'ent_coef': 7.822842560063759e-07, 'ortho_init': False, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 14:02:25,373] Trial 75 pruned. \n",
      "[I 2023-08-26 14:02:35,736] Trial 76 finished with value: 348.3333333333333 and parameters: {'gamma': 0.00013005796900841145, 'max_grad_norm': 2.247039507719428, 'gae_lambda': 0.021347337079004873, 'exponent_n_steps': 9, 'lr': 0.0033143632411587534, 'ent_coef': 6.168010059667601e-07, 'ortho_init': True, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 9 with value: 500.0.\n",
      "[I 2023-08-26 14:02:40,619] Trial 77 pruned. \n",
      "[I 2023-08-26 14:02:48,356] Trial 78 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials:  79\n",
      "Best trial:\n",
      "  Value:  500.0\n",
      "  Params: \n",
      "    gamma: 0.00014107442660152463\n",
      "    max_grad_norm: 1.9397063942552386\n",
      "    gae_lambda: 0.011699973530174844\n",
      "    exponent_n_steps: 9\n",
      "    lr: 0.006473981194686457\n",
      "    ent_coef: 4.2905282590519327e-07\n",
      "    ortho_init: False\n",
      "    net_arch: tiny\n",
      "    activation_fn: tanh\n",
      "  User attrs:\n",
      "    gamma_: 0.9998589255733985\n",
      "    gae_lambda_: 0.9883000264698252\n",
      "    n_steps: 512\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Optuna example that optimizes the hyperparameters of\n",
    "a reinforcement learning agent using A2C implementation from Stable-Baselines3\n",
    "on a Gymnasium environment.\n",
    "\n",
    "This is a simplified version of what can be found in https://github.com/DLR-RM/rl-baselines3-zoo.\n",
    "\n",
    "You can run this example as follows:\n",
    "    $ python sb3_simple.py\n",
    "\n",
    "\"\"\"\n",
    "from typing import Any\n",
    "from typing import Dict\n",
    "\n",
    "import gymnasium\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "N_TRIALS = 100\n",
    "N_STARTUP_TRIALS = 5\n",
    "N_EVALUATIONS = 2\n",
    "N_TIMESTEPS = int(2e4)\n",
    "EVAL_FREQ = int(N_TIMESTEPS / N_EVALUATIONS)\n",
    "N_EVAL_EPISODES = 3\n",
    "\n",
    "ENV_ID = \"CartPole-v1\"\n",
    "\n",
    "DEFAULT_HYPERPARAMS = {\n",
    "    \"policy\": \"MlpPolicy\",\n",
    "    \"env\": ENV_ID,\n",
    "}\n",
    "\n",
    "\n",
    "def sample_a2c_params(trial: optuna.Trial) -> Dict[str, Any]:\n",
    "    \"\"\"Sampler for A2C hyperparameters.\"\"\"\n",
    "    gamma = 1.0 - trial.suggest_float(\"gamma\", 0.0001, 0.1, log=True)\n",
    "    max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.3, 5.0, log=True)\n",
    "    gae_lambda = 1.0 - trial.suggest_float(\"gae_lambda\", 0.001, 0.2, log=True)\n",
    "    n_steps = 2 ** trial.suggest_int(\"exponent_n_steps\", 3, 10)\n",
    "    learning_rate = trial.suggest_float(\"lr\", 1e-5, 1, log=True)\n",
    "    ent_coef = trial.suggest_float(\"ent_coef\", 0.00000001, 0.1, log=True)\n",
    "    ortho_init = trial.suggest_categorical(\"ortho_init\", [False, True])\n",
    "    net_arch = trial.suggest_categorical(\"net_arch\", [\"tiny\", \"small\"])\n",
    "    activation_fn = trial.suggest_categorical(\"activation_fn\", [\"tanh\", \"relu\"])\n",
    "\n",
    "    # Display true values.\n",
    "    trial.set_user_attr(\"gamma_\", gamma)\n",
    "    trial.set_user_attr(\"gae_lambda_\", gae_lambda)\n",
    "    trial.set_user_attr(\"n_steps\", n_steps)\n",
    "\n",
    "    net_arch = [\n",
    "        {\"pi\": [64], \"vf\": [64]}\n",
    "        if net_arch == \"tiny\"\n",
    "        else {\"pi\": [64, 64], \"vf\": [64, 64]}\n",
    "    ]\n",
    "\n",
    "    activation_fn = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU}[activation_fn]\n",
    "\n",
    "    return {\n",
    "        \"n_steps\": n_steps,\n",
    "        \"gamma\": gamma,\n",
    "        \"gae_lambda\": gae_lambda,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"ent_coef\": ent_coef,\n",
    "        \"max_grad_norm\": max_grad_norm,\n",
    "        \"policy_kwargs\": {\n",
    "            \"net_arch\": net_arch,\n",
    "            \"activation_fn\": activation_fn,\n",
    "            \"ortho_init\": ortho_init,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "class TrialEvalCallback(EvalCallback):\n",
    "    \"\"\"Callback used for evaluating and reporting a trial.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        eval_env: gymnasium.Env,\n",
    "        trial: optuna.Trial,\n",
    "        n_eval_episodes: int = 5,\n",
    "        eval_freq: int = 10000,\n",
    "        deterministic: bool = True,\n",
    "        verbose: int = 0,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            eval_env=eval_env,\n",
    "            n_eval_episodes=n_eval_episodes,\n",
    "            eval_freq=eval_freq,\n",
    "            deterministic=deterministic,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        self.trial = trial\n",
    "        self.eval_idx = 0\n",
    "        self.is_pruned = False\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
    "            super()._on_step()\n",
    "            self.eval_idx += 1\n",
    "            self.trial.report(self.last_mean_reward, self.eval_idx)\n",
    "            # Prune trial if need.\n",
    "            if self.trial.should_prune():\n",
    "                self.is_pruned = True\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    kwargs = DEFAULT_HYPERPARAMS.copy()\n",
    "    # Sample hyperparameters.\n",
    "    kwargs.update(sample_a2c_params(trial))\n",
    "    # Create the RL model.\n",
    "    model = A2C(**kwargs)\n",
    "    # Create env used for evaluation.\n",
    "    eval_env = Monitor(gymnasium.make(ENV_ID))\n",
    "    # Create the callback that will periodically evaluate and report the performance.\n",
    "    eval_callback = TrialEvalCallback(\n",
    "        eval_env,\n",
    "        trial,\n",
    "        n_eval_episodes=N_EVAL_EPISODES,\n",
    "        eval_freq=EVAL_FREQ,\n",
    "        deterministic=True,\n",
    "    )\n",
    "\n",
    "    nan_encountered = False\n",
    "    try:\n",
    "        model.learn(N_TIMESTEPS, callback=eval_callback)\n",
    "    except AssertionError as e:\n",
    "        # Sometimes, random hyperparams can generate NaN.\n",
    "        print(e)\n",
    "        nan_encountered = True\n",
    "    finally:\n",
    "        # Free memory.\n",
    "        model.env.close()\n",
    "        eval_env.close()\n",
    "\n",
    "    # Tell the optimizer that the trial failed.\n",
    "    if nan_encountered:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    if eval_callback.is_pruned:\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return eval_callback.last_mean_reward\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set pytorch num threads to 1 for faster training.\n",
    "    torch.set_num_threads(1)\n",
    "\n",
    "    sampler = TPESampler(n_startup_trials=N_STARTUP_TRIALS)\n",
    "    # Do not prune before 1/3 of the max budget is used.\n",
    "    pruner = MedianPruner(\n",
    "        n_startup_trials=N_STARTUP_TRIALS, n_warmup_steps=N_EVALUATIONS // 3\n",
    "    )\n",
    "\n",
    "    study = optuna.create_study(sampler=sampler, pruner=pruner, direction=\"maximize\")\n",
    "    try:\n",
    "        study.optimize(objective, n_trials=N_TRIALS, timeout=600)\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    print(\"Number of finished trials: \", len(study.trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    print(\"  User attrs:\")\n",
    "    for key, value in trial.user_attrs.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "human-memory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
