{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_config = {\n",
    "    \"officeroom\": {\n",
    "        \"north\": \"wall\",\n",
    "        \"east\": \"livingroom\",\n",
    "        \"south\": \"wall\",\n",
    "        \"west\": \"wall\",\n",
    "    },\n",
    "    \"livingroom\": {\n",
    "        \"north\": \"wall\",\n",
    "        \"east\": \"wall\",\n",
    "        \"south\": \"bedroom\",\n",
    "        \"west\": \"officeroom\",\n",
    "    },\n",
    "    \"bedroom\": {\n",
    "        \"north\": \"livingroom\",\n",
    "        \"east\": \"wall\",\n",
    "        \"south\": \"wall\",\n",
    "        \"west\": \"wall\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "object_transition_config = {\n",
    "    \"static\": {\"bed\": None, \"desk\": None, \"table\": None},\n",
    "    \"independent\": {\n",
    "        \"tae\": {\n",
    "            \"officeroom\": {\"north\": 0, \"east\": 0.1, \"south\": 0, \"west\": 0, \"stay\": 0.9},\n",
    "            \"livingroom\": {\n",
    "                \"north\": 0,\n",
    "                \"east\": 0,\n",
    "                \"south\": 0,\n",
    "                \"west\": 0.1,\n",
    "                \"stay\": 0.9,\n",
    "            },\n",
    "            \"bedroom\": {\"north\": 0, \"east\": 0, \"south\": 0, \"west\": 0, \"stay\": 0},\n",
    "        },\n",
    "        \"michael\": {\n",
    "            \"officeroom\": {\n",
    "                \"north\": 0,\n",
    "                \"east\": 0,\n",
    "                \"south\": 0,\n",
    "                \"west\": 0,\n",
    "                \"stay\": 0,\n",
    "            },\n",
    "            \"livingroom\": {\n",
    "                \"north\": 0,\n",
    "                \"east\": 0,\n",
    "                \"south\": 0.9,\n",
    "                \"west\": 0,\n",
    "                \"stay\": 0.1,\n",
    "            },\n",
    "            \"bedroom\": {\"north\": 0.1, \"east\": 0, \"south\": 0, \"west\": 0, \"stay\": 0.9},\n",
    "        },\n",
    "        \"vincent\": {\n",
    "            \"officeroom\": {\n",
    "                \"north\": 0,\n",
    "                \"east\": 0.5,\n",
    "                \"south\": 0,\n",
    "                \"west\": 0,\n",
    "                \"stay\": 0.5,\n",
    "            },\n",
    "            \"livingroom\": {\n",
    "                \"north\": 0,\n",
    "                \"east\": 0,\n",
    "                \"south\": 0.333,\n",
    "                \"west\": 0.333,\n",
    "                \"stay\": 0.333,\n",
    "            },\n",
    "            \"bedroom\": {\n",
    "                \"north\": 0.5,\n",
    "                \"east\": 0,\n",
    "                \"south\": 0,\n",
    "                \"west\": 0,\n",
    "                \"stay\": 0.5,\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"dependent\": {\n",
    "        \"laptop\": {\"tae\": 0.7, \"michael\": 0.4, \"vincent\": 0.1},\n",
    "        \"phone\": {\"tae\": 0.1, \"michael\": 0.7, \"vincent\": 0.4},\n",
    "        \"headset\": {\"tae\": 0.4, \"michael\": 0.1, \"vincent\": 0.9},\n",
    "    },\n",
    "    \"agent\": {\n",
    "        \"agent\": {\"officeroom\": None, \"livingroom\": None, \"bedroom\": None},\n",
    "    },\n",
    "}\n",
    "\n",
    "object_init_config = {\n",
    "    \"static\": {\n",
    "        \"bed\": {\"officeroom\": 0, \"livingroom\": 0, \"bedroom\": 1},\n",
    "        \"desk\": {\"officeroom\": 1, \"livingroom\": 0, \"bedroom\": 0},\n",
    "        \"table\": {\"officeroom\": 0, \"livingroom\": 1, \"bedroom\": 0},\n",
    "    },\n",
    "    \"independent\": {\n",
    "        \"tae\": {\"officeroom\": 0.5, \"livingroom\": 0.5, \"bedroom\": 0},\n",
    "        \"michael\": {\"officeroom\": 0, \"livingroom\": 0.5, \"bedroom\": 0.5},\n",
    "        \"vincent\": {\"officeroom\": 0.333, \"livingroom\": 0.333, \"bedroom\": 0.333},\n",
    "    },\n",
    "    \"dependent\": {\n",
    "        \"laptop\": {\"officeroom\": 0.333, \"livingroom\": 0.333, \"bedroom\": 0.333},\n",
    "        \"phone\": {\"officeroom\": 0.333, \"livingroom\": 0.333, \"bedroom\": 0.333},\n",
    "        \"headset\": {\"officeroom\": 0.333, \"livingroom\": 0.333, \"bedroom\": 0.333},\n",
    "    },\n",
    "    \"agent\": {\n",
    "        \"agent\": {\"officeroom\": 0.333, \"livingroom\": 0.333, \"bedroom\": 0.333},\n",
    "    },\n",
    "}\n",
    "\n",
    "config = {\n",
    "    \"room_config\": room_config,\n",
    "    \"object_transition_config\": object_transition_config,\n",
    "    \"object_init_config\": object_init_config,\n",
    "    \"question_prob\": 1.0,\n",
    "    \"seed\": 42,\n",
    "    \"terminates_at\": 99,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.virtualenvs/human-memory/lib/python3.9/site-packages/gymnasium/envs/registration.py:491: UserWarning: \u001b[33mWARN: The environment creator metadata doesn't include `render_modes`, contains: ['render.modes']\u001b[0m\n",
      "  logger.warn(\n",
      "/home/tk/.virtualenvs/human-memory/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:197: DeprecationWarning: \u001b[33mWARN: Current gymnasium version requires that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.deprecation(\n",
      "/home/tk/.virtualenvs/human-memory/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:210: DeprecationWarning: \u001b[33mWARN: Current gymnasium version requires that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.deprecation(\n",
      "/home/tk/.virtualenvs/human-memory/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:156: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method should be an int or np.int64, actual type: <class 'tuple'>\u001b[0m\n",
      "  logger.warn(f\"{pre} should be an int or np.int64, actual type: {type(obs)}\")\n",
      "/home/tk/.virtualenvs/human-memory/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:188: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/home/tk/.virtualenvs/human-memory/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:156: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method should be an int or np.int64, actual type: <class 'tuple'>\u001b[0m\n",
      "  logger.warn(f\"{pre} should be an int or np.int64, actual type: {type(obs)}\")\n",
      "/home/tk/.virtualenvs/human-memory/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:188: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import random\n",
    "\n",
    "env = gym.make(\"room_env:RoomEnv-v2\", **config)\n",
    "(obs, question), info = env.reset()\n",
    "rewards = []\n",
    "obs_all = []\n",
    "while True:\n",
    "    action_qa = \"livingroom\"\n",
    "    action_explore = random.choice([\"north\", \"east\", \"south\", \"west\", \"stay\"])\n",
    "    (obs, question), reward, done, truncated, info = env.step((\"wall\", action_explore))\n",
    "    rewards.append(reward)\n",
    "    obs_all.append(obs)\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(obs) for obs in obs_all]), min([len(obs) for obs in obs_all])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['livingroom', 'tothenorth', 'wall', 100],\n",
       "  ['livingroom', 'totheeast', 'wall', 100],\n",
       "  ['livingroom', 'tothesouth', 'bedroom', 100],\n",
       "  ['livingroom', 'tothewest', 'officeroom', 100],\n",
       "  ['table', 'atlocation', 'livingroom', 100],\n",
       "  ['vincent', 'atlocation', 'livingroom', 100],\n",
       "  ['headset', 'atlocation', 'livingroom', 100],\n",
       "  ['agent', 'atlocation', 'livingroom', 100]],\n",
       " ['table', 'atlocation', '?', 100])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs, question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['livingroom', 'tothenorth', 'wall', 100],\n",
       " ['livingroom', 'totheeast', 'wall', 100],\n",
       " ['livingroom', 'tothesouth', 'bedroom', 100],\n",
       " ['livingroom', 'tothewest', 'officeroom', 100],\n",
       " ['table', 'atlocation', 'livingroom', 100],\n",
       " ['vincent', 'atlocation', 'livingroom', 100],\n",
       " ['headset', 'atlocation', 'livingroom', 100],\n",
       " ['agent', 'atlocation', 'livingroom', 100]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['officeroom', 'tothenorth', 'wall', 100],\n",
       " ['officeroom', 'totheeast', 'livingroom', 100],\n",
       " ['officeroom', 'tothesouth', 'wall', 100],\n",
       " ['officeroom', 'tothewest', 'wall', 100],\n",
       " ['livingroom', 'tothenorth', 'wall', 100],\n",
       " ['livingroom', 'totheeast', 'wall', 100],\n",
       " ['livingroom', 'tothesouth', 'bedroom', 100],\n",
       " ['livingroom', 'tothewest', 'officeroom', 100],\n",
       " ['bedroom', 'tothenorth', 'livingroom', 100],\n",
       " ['bedroom', 'totheeast', 'wall', 100],\n",
       " ['bedroom', 'tothesouth', 'wall', 100],\n",
       " ['bedroom', 'tothewest', 'wall', 100],\n",
       " ['bed', 'atlocation', 'bedroom', 100],\n",
       " ['desk', 'atlocation', 'officeroom', 100],\n",
       " ['table', 'atlocation', 'livingroom', 100],\n",
       " ['tae', 'atlocation', 'officeroom', 100],\n",
       " ['michael', 'atlocation', 'bedroom', 100],\n",
       " ['vincent', 'atlocation', 'livingroom', 100],\n",
       " ['laptop', 'atlocation', 'officeroom', 100],\n",
       " ['phone', 'atlocation', 'bedroom', 100],\n",
       " ['headset', 'atlocation', 'livingroom', 100],\n",
       " ['agent', 'atlocation', 'livingroom', 100]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.hidden_global_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39moptim\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m \u001b[39mimport\u001b[39;00m clear_output\n\u001b[0;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnn\u001b[39;00m \u001b[39mimport\u001b[39;00m LSTM\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm, trange\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mexplicit_memory\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmemory\u001b[39;00m \u001b[39mimport\u001b[39;00m EpisodicMemory, SemanticMemory, ShortMemory\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nn'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "from explicit_memory.memory import EpisodicMemory, SemanticMemory, ShortMemory\n",
    "from explicit_memory.policy import answer_question, encode_observation, manage_memory\n",
    "from explicit_memory.utils import ReplayBuffer, is_running_notebook, write_yaml\n",
    "\n",
    "\n",
    "class HandCraftedAgent:\n",
    "    \"\"\"Handcrafted agent interacting with environment.\n",
    "\n",
    "    This agent explores the roooms, i.e., KGs. The exploration can be uniform-random,\n",
    "    or just avoiding walls.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        env_str: str = \"room_env:RoomEnv-v2\",\n",
    "        env_config: dict = None,\n",
    "        memory_management_policy: str = \"episodic_semantic\",\n",
    "        qa_policy: str = \"episodic_semantic\",\n",
    "        explore_policy: str = \"random\",\n",
    "        num_samples_for_results: int = 10,\n",
    "        capacity: dict = {\n",
    "            \"episodic\": 4,\n",
    "            \"semantic\": 4,\n",
    "            \"short\": 16,\n",
    "        },\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize the agent.\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        env_str: This has to be \"room_env:RoomEnv-v2\"\n",
    "        env_config: The configuration of the environment.\n",
    "        memory_management_policy: Memory management policy.\n",
    "        qa_policy: question answering policy\n",
    "        policy: The room exploration policy. Choose one of \"random\", \"avoid_walls\"\n",
    "        num_samples_for_results: The number of samples to validate / test the agent.\n",
    "        capacity: The capacity of each human-like memory systems.\n",
    "\n",
    "        \"\"\"\n",
    "        self.all_params = deepcopy(locals())\n",
    "        del self.all_params[\"self\"]\n",
    "        self.env_str = env_str\n",
    "        self.env_config = env_config\n",
    "        self.memory_management_policy = memory_management_policy\n",
    "        self.qa_policy = qa_policy\n",
    "        self.explore_policy = explore_policy\n",
    "        self.num_samples_for_results = num_samples_for_results\n",
    "        self.capacity = capacity\n",
    "\n",
    "        self.env = gym.make(self.env_str, **env_config)\n",
    "\n",
    "        self.default_root_dir = f\"./training_results/{str(datetime.datetime.now())}\"\n",
    "        os.makedirs(self.default_root_dir, exist_ok=True)\n",
    "\n",
    "    def init_memory_systems(self, num_actions: int = 5) -> None:\n",
    "        \"\"\"Initialize the agent's memory systems. This has nothing to do with the\n",
    "        replay buffer.\"\"\"\n",
    "        self.action_space = gym.spaces.Discrete(num_actions)\n",
    "        self.memory_systems = {\n",
    "            \"episodic\": EpisodicMemory(capacity=self.capacity[\"episodic\"]),\n",
    "            \"semantic\": SemanticMemory(capacity=self.capacity[\"semantic\"]),\n",
    "            \"short\": ShortMemory(capacity=self.capacity[\"short\"]),\n",
    "        }\n",
    "\n",
    "    def get_memory_state(self) -> dict:\n",
    "        \"\"\"Return the current state of the memory systems. This is NOT what the gym env\n",
    "        gives you. This is made by the agent.\n",
    "\n",
    "        \"\"\"\n",
    "        state_as_dict = {\n",
    "            \"episodic\": self.memory_systems[\"episodic\"].return_as_lists(),\n",
    "            \"semantic\": self.memory_systems[\"semantic\"].return_as_lists(),\n",
    "            \"short\": self.memory_systems[\"short\"].return_as_lists(),\n",
    "        }\n",
    "        return state_as_dict\n",
    "\n",
    "    def encode_all_observations(self, observations: List[List[str]]) -> None:\n",
    "        \"\"\"Encode all observations to the short-term memory systems.\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        observations: A list of list of quadruples.\n",
    "\n",
    "        \"\"\"\n",
    "        for obs in observations:\n",
    "            encode_observation(self.memory_systems, obs)\n",
    "\n",
    "    def test(self):\n",
    "        \"\"\"Test the agent. There is no training for this agent, since it is\n",
    "        handcrafted.\"\"\"\n",
    "        self.scores = []\n",
    "        for _ in range(self.num_samples_for_results):\n",
    "            self.init_memory_systems()\n",
    "            (observations, self.question), info = self.env.reset()\n",
    "            self.encode_all_observations(observations)\n",
    "\n",
    "            self.manage_memory(observations)\n",
    "\n",
    "            done = False\n",
    "            score = 0\n",
    "            while not done:\n",
    "                if self.policy.lower() == \"random\":\n",
    "                    selected_action = random.choice([\"episodic\", \"semantic\", \"forget\"])\n",
    "                    manage_memory(self.memory_systems, selected_action)\n",
    "                    qa_policy = \"episodic_semantic\"\n",
    "                elif self.policy.lower() == \"episodic_only\":\n",
    "                    manage_memory(self.memory_systems, \"episodic\")\n",
    "                    qa_policy = \"episodic\"\n",
    "                elif self.policy.lower() == \"semantic_only\":\n",
    "                    qa_policy = \"semantic\"\n",
    "                    manage_memory(self.memory_systems, \"semantic\")\n",
    "                else:\n",
    "                    raise ValueError(\"Unknown policy.\")\n",
    "\n",
    "                answer = str(\n",
    "                    answer_question(self.memory_systems, qa_policy, self.question)\n",
    "                ).lower()\n",
    "                (\n",
    "                    (observation, self.question),\n",
    "                    reward,\n",
    "                    done,\n",
    "                    truncated,\n",
    "                    info,\n",
    "                ) = self.env.step(answer)\n",
    "\n",
    "                encode_observation(self.memory_systems, observation)\n",
    "                score += reward\n",
    "            self.scores.append(score)\n",
    "\n",
    "        results = {\n",
    "            \"test_score\": {\n",
    "                \"mean\": round(np.mean(self.scores).item(), 2),\n",
    "                \"std\": round(np.std(self.scores).item(), 2),\n",
    "            }\n",
    "        }\n",
    "        write_yaml(results, os.path.join(self.default_root_dir, \"results.yaml\"))\n",
    "        write_yaml(self.all_params, os.path.join(self.default_root_dir, \"train.yaml\"))\n",
    "        write_yaml(\n",
    "            self.get_memory_state(),\n",
    "            os.path.join(self.default_root_dir, \"last_memory_state.yaml\"),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['asdf', 'bar', 'baz', 'qux']]\n"
     ]
    }
   ],
   "source": [
    "def foo(foo: List[List[str]]) -> None:\n",
    "    print(foo)\n",
    "\n",
    "\n",
    "foo([[\"asdf\", \"bar\", \"baz\", \"qux\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "human-memory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
